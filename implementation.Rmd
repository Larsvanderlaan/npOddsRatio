---
title: "code"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
fit$coefs[,1,drop=F]
fit1$coefs[,1,drop=F]
#2.840103398, 0.496371343
 
 
```
 
```{r}
n <- 100000
  D <- DAG.empty()
  D <- D +
    node("W1", distr = "runif", min = -1, max = 1) +
    node("W2", distr = "runif", min = -1, max = 1) +
    node("A", distr = "rbinom", size = 1, prob = plogis(W1 + W2) )+
    node("Z1", distr = "rgamma", shape=3, rate = 2) +
     node("Z", distr = "rconst", const=min(Z1,4)) +
    node("Q", distr = "rconst", const = plogis(-1+A + A*(-1.5*W1  -2*(Z-1.5)*(Z<=1.5) + 2*W1*Z   ) + 0.5*W1+ (Z-1.3) + (Z-1.5)*(Z>=1.5) *(1.5+W1) + (Z-2.5)*(Z>=2.5)+ 0.5*W2))+
    
    node("Y", distr = "rbinom", size = 1, prob = Q) + 
     node("G", distr = "rconst",const = 1- 0.7*plogis(0.4*(W1 + W2  +A-0.5) + (Z-1.3)*(2.5+W1) + 2*(Z-2)*(Z>=2) ))+
    node("Delta", distr = "rbinom", size = 1, prob = G)
 
  setD <- set.DAG(D )
  data <- sim(setD, n = n)
  quantile(data$Z)
  table(data$Delta)
  quantile(data$Q)
  quantile(data$Q)


  lrnr <- Lrnr_gam$new()
  
  true <- c(2, 1)
  require(doMC)
  registerDoMC()
  fit <- npOR(~ poly(W1,degree=1, raw = T)    , W = data[,c("W1", "W2")], A = data$A, Y = data$Y , num_knots_Y0W = c(30,20,1), max_degree_Y0W = 3, sl3_learner_A = lrnr, fit_control = list(parallel = T) )
  data$Y <- data$Y*data$Delta
  fit1 <- npOR(~ poly(W1,degree=1, raw = T)    , W = data[,c("W1", "W2")], A = data$A, Y = data$Y , Delta = data$Delta, num_knots_Y0W = c(30,20,1), max_degree_Y0W = 3, sl3_learner_A = lrnr,fit_control = list(parallel = T)  )
```


```{r, include = F, echo = F}
library(sl3)
library(simcausal)
library(hal9001)
 passes1 <- c()
 passes2 <- c()
for(i in 1:500){
  n <- 3500
  D <- DAG.empty()
  D <- DAG.empty()
  D <- D +
    node("W1", distr = "runif", min = -1, max = 1) +
    node("W2", distr = "runif", min = -1, max = 1) +
    node("A", distr = "rbinom", size = 1, prob = plogis(W1 + W2) )+
    node("Z1", distr = "rgamma", shape=3, rate = 2) +
     node("Z", distr = "rconst", const=min(Z1,4)) +
    node("Q", distr = "rconst", const = plogis(-1+A + A*(-1.5*W1  -2*(Z-1.5)*(Z<=1.5) + 2*W1*Z   ) + 0.5*W1+ (Z-1.3) + (Z-1.5)*(Z>=1.5) *(1.5+W1) + (Z-2.5)*(Z>=2.5)+ 0.5*W2))+
    
    node("Y", distr = "rbinom", size = 1, prob = Q) + 
     node("G", distr = "rconst",const = 1- 0.7*plogis(0.4*(W1 + W2  +A-0.5) + (Z-1.3)*(2.5+W1) + 2*(Z-2)*(Z>=2) ))+
    node("Delta", distr = "rbinom", size = 1, prob = G)
 
  setD <- set.DAG(D )
  data <- sim(setD, n = n)
  data$Y <- data$Y * data$Delta
  true <- c(1.3104008, 0.9977911)
   library(doMC)
  registerDoMC(8)
  #fit <- npOR(~1 + W1^2 + W2^2, W = data[,c("W1", "W2")], A = data$A, Y = data$Y, glm_formula_A = ~ .^2, glm_formula_Y = ~ .^2  )
  fit <- npORmissing(~ poly(W1,degree=1, raw = T)   , W = data[,c("W1", "W2")], A = data$A, Y = data$Y , Z =  rbinom(n,size=1,prob=0.5),
                     Delta = data$Delta, num_knots_Y0W = c(30,10,1), max_degree_Y0W = 3, sl3_learner_Delta = Lrnr_hal9001_custom$new(max_degree=2,num_knots = c(20,1)), sl3_learner_A = Lrnr_hal9001_custom$new(max_degree=2,num_knots = c(20,1)),fit_control = list(parallel = T)  )
  ci <- fit$coefs
  
  passes1 <- cbind(passes1, ci[,3] <= true & ci[,4] >= true)
  
  fit <- npORmissing(~ poly(W1,degree=1, raw = T)   , W = data[,c("W1", "W2")], A = data$A, Y = data$Y , Z =  data$Z,
                     Delta = data$Delta, num_knots_Y0W = c(30,10,1), max_degree_Y0W = 3, sl3_learner_Delta = Lrnr_hal9001_custom$new(max_degree=2,num_knots = c(20,1)), sl3_learner_A = Lrnr_hal9001_custom$new(max_degree=2,num_knots = c(20,1)),fit_control = list(parallel = T)  )
  ci <- fit$coefs
  
  passes2 <- cbind(passes2, ci[,3] <= true & ci[,4] >= true)
  
  
  print(rowMeans(passes1))
  print(rowMeans(passes2))
  print(apply(passes1,1,table))
  print(apply(passes2,1,table))
}
```

```{r}
colMeans_safe <- function(X) {
  X <- as.matrix(X)
  if(ncol(X)==1){
    return(mean(as.vector(X)))
  }
  return(colMeans(X))
}
bound <- function(x, b){
  pmax(pmin(x,1-b),b)
}

npORmissing <- function(formula = logOR~1, W, A, Y, Z, Delta, weights = NULL, W_new = W, glm_formula_A = NULL, sl3_learner_A = NULL, glm_formula_Delta= NULL, sl3_learner_Delta = NULL,  sl3_learner_YZ = NULL, glm_formula_YZ = NULL, glm_formula_Y_W = NULL, smoothness_order_Y = 1, max_degree_Y = 2, num_knots_Y = c(20,5), reduce_basis = 1e-3, fit_control = list(), ... ) {
  W <- as.matrix(W)
  Z <- as.matrix(Z)
  if(is.null(Delta)) {
    Delta <- rep(1, nrow(W))
  }
  
  n <- nrow(W)
  formula <- as.formula(formula)
  V <- model.matrix(formula, data = as.data.frame(W))
  V_new <- model.matrix(formula, data = as.data.frame(W_new))
  if(is.null(weights)) {
    weights <- rep(1, nrow(W))
  } 
  
  keep <- Delta==1
  
  #################################### 
  ############ Default learners ############ 
  #################################### 
  if(is.null(sl3_learner_A)){
    sl3_learner_A <- Lrnr_hal9001$new(smoothness_orders = smoothness_order_Y, max_degree = max_degree_Y, num_knots = num_knots_Y,   reduce_basis = reduce_basis, ...)
  }
  if(is.null(sl3_learner_Delta)){
    sl3_learner_Delta <- Lrnr_hal9001$new(smoothness_orders = smoothness_order_Y, max_degree = max_degree_Y, num_knots = num_knots_Y,   reduce_basis = reduce_basis, ...)
  }
  if(is.null(sl3_learner_YZ)){
    sl3_learner_YZ <- Lrnr_hal9001$new(smoothness_orders = smoothness_order_Y, max_degree = max_degree_Y, num_knots = num_knots_Y,   reduce_basis = reduce_basis, ...)
  }
  
  ################################################################################################
  #### Learn P(Y=1|Z, A,W)  #########################
  ################################################################################################
  print("Learning barQ")
  if(is.null(glm_formula_YZ)){
    # If no formula use HAL and respect model constraints.
    data_YZ <- data.frame(W, A, Z)
    covariates_YZ <- c(paste0("W", 1:ncol(W)), "A",paste0("Z", 1:ncol(Z)))
    colnames(data_YZ) <- c(covariates_YZ)
    data_YZ$Y <- Y
    data_YZ$weights <- weights
    task_YZ <- sl3_Task$new(data_YZ, covariates = covariates_YZ, outcome = "Y", outcome_type = "binomial", weights = "weights" ) 
    data_YZ0 <- data_YZ
    data_YZ0$A <- 0
    task_YZ0 <- sl3_Task$new(data_YZ0, covariates = covariates_YZ, outcome = "Y", outcome_type = "binomial", weights = "weights" ) 
    data_YZ1 <- data_YZ
    data_YZ1$A <- 1
    task_YZ1 <- sl3_Task$new(data_YZ1, covariates = covariates_YZ, outcome = "Y", outcome_type = "binomial", weights = "weights" ) 
    fit_YZ <- sl3_learner_YZ$train(task_YZ[keep])
    barQ <- fit_YZ$predict(task_YZ)
    print(quantile(barQ))
    barQ1 <- fit_YZ$predict(task_YZ1)
    barQ0 <- fit_YZ$predict(task_YZ0)
  } else {
    # Use glm if formula supplied
    
    W_np <- model.matrix(glm_formula_YZ, data = as.data.frame(cbind(W,Z)))
    X <- cbind(W_np, A*W_np)
    X1 <- cbind(W_np, 1*W_np)
    X0 <- cbind(W_np, 0*W_np)
    fit_Y <- glm.fit(X,Y, weights = Delta*weights, family = binomial(), intercept = F)
    cfs <- coef(fit_Y)
    barQ <- as.vector(plogis(X%*%cfs))
    barQ1 <- as.vector(plogis(X1%*%cfs))
    barQ0 <- as.vector(plogis(X0%*%cfs))
  }
  
  print("Learning Q")
  ################################################################################################
  #### Learn P(Y=1|A,X) under partially linear logistic model assumption #########################
  ################################################################################################
  if(is.null(glm_formula_Y_W)){
    # If no formula use HAL and respect model constraints.
    fit_control$weights <- weights
    fit_Y <- suppressWarnings(fit_hal(X = as.matrix(W), X_unpenalized = as.matrix(A*V),
                      Y = as.vector(barQ), family = binomial(), fit_control = fit_control, smoothness_orders = smoothness_order_Y, max_degree = max_degree_Y, num_knots = num_knots_Y, ...))
    Q <- predict(fit_Y, new_data = as.matrix(W), new_X_unpenalized = as.matrix(A*V))
    Q0 <- predict(fit_Y, new_data = as.matrix(W), new_X_unpenalized = as.matrix(0*V))
    Q1 <- predict(fit_Y, new_data = as.matrix(W), new_X_unpenalized = as.matrix(1*V))
    print(quantile(Q))
  } else {
    # Use glm if formula supplied
    W_np <- model.matrix(glm_formula_Y_W, data = as.data.frame(W))
    X <- cbind(W_np, A*V)
    X1 <- cbind(W_np, 1*V)
    X0 <- cbind(W_np, 0*V)
    fit_Y <- glm.fit(X,barQ, weights = weights, family = binomial(), intercept = F)
    cfs <- coef(fit_Y)
    Q <- as.vector(plogis(X%*%cfs))
    Q1 <- as.vector(plogis(X1%*%cfs))
    Q0 <- as.vector(plogis(X0%*%cfs))
  }
  
  ################################
  #### Learn P(A=1|X) ############
  ################################
   
  # If no glm formula then use sl3 learner.
  if(is.null(glm_formula_Delta)) {
    
    data_Delta <- data.frame(W, A, Z)
    covariates_Delta  <- c(paste0("W", 1:ncol(W)), "A",paste0("Z", 1:ncol(Z)))
    colnames(data_Delta ) <- covariates_Delta 
    data_Delta$Delta <- Delta
    data_Delta$weights <- weights
    task_Delta <- sl3_Task$new(data_Delta, covariates = covariates_Delta, outcome = "Delta", outcome_type = "binomial", weights = "weights" ) 
    fit_Delta <- sl3_learner_Delta$train(task_Delta)
    G <- fit_Delta$predict(task_Delta)
    print(range(G))
    G <- bound(G, 0.005)
  } else {
    # use glm is formula supplied
    W_np <- model.matrix(glm_formula_Delta, data = as.data.frame(cbind(W,Z)))
    X <- cbind(W_np, A*W_np)
    X1 <- cbind(W_np, 1*W_np)
    X0 <- cbind(W_np, 0*W_np)
    fit_Delta<- glm.fit(X,Delta, weights = weights, family = binomial(), intercept = F)
    cfs <- coef(fit_Delta)
    G <- as.vector(plogis(X%*%cfs))
    G <- pmin(G, 0.005)
  }
  if(is.null(glm_formula_A)) {
    
    data_A <- data.frame(W, A)
    covariates_A <- paste0("W", 1:ncol(W))
    colnames(data_A) <- c(covariates_A, "A")
    data_A$weights <- weights
    task_A <- sl3_Task$new(data_A, covariates = covariates_A, outcome = "A", outcome_type = "binomial", weights = "weights" )
    fit_A <- sl3_learner_A$train(task_A)
    g1 <- fit_A$predict(task_A)
  } else {
    # use glm is formula supplied
    W_g <- model.matrix(glm_formula_A, data = as.data.frame(W))
    fit_A <- glm.fit(W_g,A, weights = weights, family = binomial(), intercept = F)
    cfs <- coef(fit_A)
    g1 <- as.vector(plogis(W_g%*%cfs))
  }
  
  
  
  
  
  
  ################################
  ##### Targeting Step ###########
  ################################
  converged_flag <- FALSE
  for(i in 1:50) {
     
    
    ################################
    ##### Update  Q ###########
    ################################
    for(j in 1:10) {
       
      h_star <- V* as.vector(-(g1*Q1*(1-Q1)) / (g1*Q1*(1-Q1) + (1-g1)*Q0*(1-Q0)))
      H_star <- (A*V + h_star)
      H_star1 <- (V + h_star)
      H_star0 <-  h_star
      scale <- apply(V,2, function(v){colMeans_safe(weights*as.vector( Q1*(1-Q1) * Q0*(1-Q0) * g1 * (1-g1) / (g1 * Q1*(1-Q1) + (1-g1) *Q0*(1-Q0) )) * v*V)})
      scale_inv <- solve(scale)
      var_unscaled <- as.matrix(var(weights*H_star*(Y-Q)))
      var_scaled <-  scale_inv %*% var_unscaled  %*%  t(scale_inv)
       
      score <- sum(abs(colMeans_safe(weights*H_star%*%scale_inv*as.vector(barQ-Q)) ))
      print("Inner")
      print(score)
      if(abs(score) <= min(0.5,0.5*mean(sqrt(diag(var_scaled))))/sqrt(n)/log(n)){
        break
      }
      offset <- qlogis(Q)
      eps <- coef(suppressWarnings(glm(Y~X-1, family = binomial(), weights = weights, offset = offset, data = list(Y = barQ, X = H_star))))
      Q <- as.vector(plogis(offset +  H_star %*% eps))
      Q0 <- as.vector(plogis(qlogis(Q0) +  H_star0 %*% eps ))
      Q1 <- as.vector(plogis(qlogis(Q1) +  H_star1 %*% eps))
    }
    
     ################################
    ##### Update barQ ###########
    ################################
    h_star <- V* as.vector(-(g1*Q1*(1-Q1)) / (g1*Q1*(1-Q1) + (1-g1)*Q0*(1-Q0)))
    H_star <- (A*V + h_star)
    H_star1 <- (V + h_star)
    H_star0 <-  h_star
    
    scale <- apply(V,2, function(v){colMeans_safe(weights*as.vector( Q1*(1-Q1) * Q0*(1-Q0) * g1 * (1-g1) / (g1 * Q1*(1-Q1) + (1-g1) *Q0*(1-Q0) )) * v*V)})
    scale_inv <- solve(scale)
    var_unscaled <- as.matrix(var(weights*H_star*(Y-Q)))
    var_scaled <-  scale_inv %*% var_unscaled  %*%  t(scale_inv)
     
    offset <- qlogis(barQ)
    eps <- coef(suppressWarnings(glm(Y~X-1, family = binomial(), weights = Delta*weights/G, offset = offset, data = list(Y = Y, X = H_star))))
    barQ <- as.vector(plogis(offset +  H_star %*% eps))
    barQ0 <- as.vector(plogis(qlogis(barQ0) +  H_star0 %*% eps ))
    barQ1 <- as.vector(plogis(qlogis(barQ1) +  H_star1 %*% eps))
    
    
    ################################
    ##### Check convergence ###########
    ################################
    h_star <- -V* as.vector((g1*Q1*(1-Q1)) / (g1*Q1*(1-Q1) + (1-g1)*Q0*(1-Q0)))
      H_star <- (A*V + h_star)
      H_star1 <- (V + h_star)
      H_star0 <-  h_star
       
      scale <- apply(V,2, function(v){colMeans_safe(weights*as.vector(Q1*(1-Q1) * Q0*(1-Q0) * g1 * (1-g1) / (g1 * Q1*(1-Q1) + (1-g1) *Q0*(1-Q0) )) * v*V)})
      scale_inv <- solve(scale)
      EIF1 <- (Delta/G)*weights*H_star%*%scale_inv*as.vector(Y-barQ)
      EIF2 <- weights*H_star%*%scale_inv*as.vector(barQ-Q)
      EIF <- EIF1 + EIF2
      
      var_scaled <- as.matrix(var(EIF))
      #var_scaled <-  scale_inv %*% var_unscaled  %*%  t(scale_inv)
       
      score <- sum(abs(colMeans_safe(EIF1 + EIF2 )))
       
      print(score)
      if(score <= min(0.5,0.5*mean(sqrt(diag(var_scaled))))/sqrt(n)/log(n)) {
        print("converged")
        converged_flag <- TRUE
        break
      }
    
    
    
  }
  
   
  # Cheap way of extracting coefficients.
  logOR <- log((Q1*(1-Q0)/((1-Q1)*(Q0))))
  
  estimates <- as.vector(coef(suppressWarnings(glm(logOR~V-1, family = gaussian(), data = list(V=V, logOR = logOR )))))
  
   
  
  var_scaled <-  var_scaled
   
  
  compute_predictions <- function(W_newer) {
    V_newer <- model.matrix(formula, data = as.data.frame(W_newer))
    est_grid <-V_newer%*%estimates
    se_grid <- apply(V_newer,1, function(m) {
      sqrt(sum(m * (var_scaled %*%m)))
    } )
    preds_new <- data.frame(W_newer, estimate = est_grid, se = se_grid, lower_CI = est_grid - 1.96*se_grid/sqrt(n), upper_CI = est_grid + 1.96*se_grid/sqrt(n))
    return(preds_new)
  }
  
  preds_new <- compute_predictions(W_new)
  
  se <- sqrt(diag(var_scaled))
  ci <- cbind(estimates, se, estimates - 1.96*se/sqrt(n), estimates + 1.96*se/sqrt(n))
  colnames(ci) <- c("coefs", "se", "lower_CI", "upper_CI")
  output <- list(coefs = ci, var_mat = var_scaled, logOR_at_W_new = preds_new, pred_function = compute_predictions,   learner_fits = list(A = fit_A, Y = fit_Y), converged_flag = converged_flag)
  return(output)
  #######
  
}


```

```{r }
library(sl3)
library(simcausal)
library(hal9001)
passes <- c()
for(i in 1:100){
  
  n <- 1500
  D <- DAG.empty()
  D <- D +
    node("W1", distr = "runif", min = -1, max = 1) +
    node("W2", distr = "runif", min = -1, max = 1) +
    node("A", distr = "rbinom", size = 1, prob = plogis(W1 + W2) )+
    node("Q", distr = "rconst", const = plogis(A + A*(W1^2) + sin(5*W1) + cos(4*W2)))+
    node("Q1", distr = "rconst", const = plogis(1 + (W1^2) + sin(5*W1) + cos(4*W2)))+
    node("Q0", distr = "rconst", const = plogis(0 + sin(5*W1) + cos(4*W2)))+
    node("OR", distr = "rconst", const = Q1*(1-Q0)/(Q0*(1-Q1)))+
    node("Y", distr = "rbinom", size = 1, prob = Q)
  true <- c(1,1)
  setD <- set.DAG(D )
  data <- sim(setD, n = n)
  data1 <- data
  data0 <- data
  data1$A <- 1
  data0$A <- 0
  task_A <- sl3_Task$new(data, covariates = c("W1", "W2"), outcome = "A")
  task_Y <- sl3_Task$new(data, covariates = c("W1", "W2", "A"), outcome = "Y")
  task_Y1 <- sl3_Task$new(data1, covariates = c("W1", "W2", "A"), outcome = "Y")
  task_Y0 <- sl3_Task$new(data0, covariates = c("W1", "W2", "A"), outcome = "Y")
  lrnr_A <- Lrnr_hal9001_custom$new(smoothness_orders = 1, num_knots = c(15,1), formula_hal = "Y~h(.) + h(.,.)", formula_control = list(exclusive_dot = TRUE))
  lrnr_Y <- Lrnr_hal9001_custom$new(smoothness_orders = 1, num_knots = c(15,8), formula_hal = "Y~h(.) + h(.,.) + h(A) ", formula_control = list(exclusive_dot = TRUE))
  lrnr_A <- lrnr_A$train(task_A)
  lrnr_Y <- lrnr_Y$train(task_Y)
  
  g1 <- lrnr_A$predict(task_A)
  Q1 <- as.vector(lrnr_Y$predict(task_Y1))
  Q0 <- as.vector(lrnr_Y$predict(task_Y0))
  Q <- as.vector(lrnr_Y$predict(task_Y))
  
  A <- data$A
  Y <- data$Y
  V <- cbind(rep(1, nrow(data)), data$W1^2) 
  
  
  
  
  
  for(i in 1:5) {
    print(i)
    h_star <- V* as.vector(-(g1*Q1*(1-Q1)) / (g1*Q1*(1-Q1) + (1-g1)*Q0*(1-Q0)))
    H_star <- (A*V + h_star)
    H_star1 <- (V + h_star)
    H_star0 <- ( h_star)
    offset <- qlogis(Q)
    
    scale <- apply(V,2,function(v) {
      
      colMeans_safe(-V* v*( -1*g1*(Q1*(1-Q1)^2 - Q1^2*(1-Q1)) / (g1*Q1*(1-Q1) + (1-g1)*Q0*(1-Q0) )  -
                              (-1*g1*Q1*(1-Q1)*(Q1*(1-Q1)^2 - Q1^2*(1-Q1))) / (g1*Q1*(1-Q1) + (1-g1)*Q0*(1-Q0) )^2 
      )*(Y-Q)  + (A*V - V*(g1*Q1*(1-Q1)) / (g1*Q1*(1-Q1) + (1-g1)*Q0*(1-Q0)))*A*v*Q*(1-Q))
    })
    scale_inv <- solve(scale)
    var_unscaled <- as.matrix(var(H_star*(Y-Q)))
    #var_unscaled_inv <- solve(var_unscaled)
    #var_scaled_inv <- t(scale) %*% var_unscaled_inv  %*%  scale
    var_scaled <-  scale_inv %*% var_unscaled  %*%  t(scale_inv)
    
    score <- sum(colMeans(H_star%*%scale_inv*as.vector(Y-Q)) )
    print(abs(score))
    if(abs(score) <= 1/sqrt(n)/log(n)){
      print("converged")
      break
    }
    eps <- coef(suppressWarnings(glm(Y~X-1, family = binomial(), offset = offset, data = list(Y = Y, X = H_star))))
    Q <- as.vector(plogis(offset +  H_star %*% eps))
    Q0 <- as.vector(plogis(qlogis(Q0) +  H_star0 %*% eps ))
    Q1 <- as.vector(plogis(qlogis(Q1) +  H_star1 %*% eps))
    #print(quantile(Q1*(1-Q0)/((1-Q1)*(Q0))))
    
  }
  
  h_star <- V* -(g1*Q1*(1-Q1)) / (g1*Q1*(1-Q1) + (1-g1)*Q0*(1-Q0))
  H_star <- (A*V + h_star)
  logOR <- log((Q1*(1-Q0)/((1-Q1)*(Q0))))
  est <- coef(suppressWarnings(glm(logOR~V-1, family = gaussian(), data = list(logOR = logOR, V = V) )))
  print(est)
  
  
  
  scale <- apply(V,2,function(v) {
    
    colMeans(-V* v*( -1*g1*(Q1*(1-Q1)^2 - Q1^2*(1-Q1)) / (g1*Q1*(1-Q1) + (1-g1)*Q0*(1-Q0) )  -
                       (-1*g1*Q1*(1-Q1)*(Q1*(1-Q1)^2 - Q1^2*(1-Q1))) / (g1*Q1*(1-Q1) + (1-g1)*Q0*(1-Q0) )^2 
    )*(Y-Q)  + (A*V - V*(g1*Q1*(1-Q1)) / (g1*Q1*(1-Q1) + (1-g1)*Q0*(1-Q0)))*A*v*Q*(1-Q))
  })
  scale_inv <- solve(scale)
  var_unscaled <- as.matrix(var(H_star*(Y-Q)))
  #var_unscaled_inv <- solve(var_unscaled)
  #var_scaled_inv <- t(scale) %*% var_unscaled_inv  %*%  scale
  var_scaled <-  scale_inv %*% var_unscaled  %*%  t(scale_inv)
  
  
  grid <- seq(-1,1,length = 10)
  M <- cbind(rep(1,10), grid^2)
  est_grid <-M%*%est
  se_grid <- apply(M,1, function(m) {
    sum(m * (var_scaled %*%m))
  } )
  
  dat <- data.frame(x = grid, est = est_grid, lower = est_grid - 1.96*se_grid/sqrt(n), upper = est_grid + 1.96*se_grid/sqrt(n))
  print(ggplot(dat, aes(x=grid, y = est)) + geom_line() +geom_ribbon(aes(ymin=lower, ymax=upper), alpha=0.2))
  
  
  se <- sqrt(diag(var_scaled))
  ci <- cbind(est, est - 1.96*se/sqrt(n), est + 1.96*se/sqrt(n))
  print(ci)
  passes <- cbind(passes, ci[,2] <= true & ci[,3] >= true)
  print(rowMeans(passes))
  print(apply(passes,1,table))
}
```








